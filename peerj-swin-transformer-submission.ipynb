{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Image classification with Swin Transformers"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-12-17T11:54:21.886996Z","iopub.status.busy":"2023-12-17T11:54:21.886669Z","iopub.status.idle":"2023-12-17T11:54:42.799634Z","shell.execute_reply":"2023-12-17T11:54:42.798438Z","shell.execute_reply.started":"2023-12-17T11:54:21.886934Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow-addons in /opt/conda/lib/python3.7/site-packages (0.14.0)\n","Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.19.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","     |████████████████████████████████| 1.1 MB 4.3 MB/s            \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /opt/conda/lib/python3.7/site-packages (from tensorflow-addons) (2.13.3)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from tensorflow-addons) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->tensorflow-addons) (3.0.6)\n","Installing collected packages: tensorflow-addons\n","  Attempting uninstall: tensorflow-addons\n","    Found existing installation: tensorflow-addons 0.14.0\n","    Uninstalling tensorflow-addons-0.14.0:\n","      Successfully uninstalled tensorflow-addons-0.14.0\n","Successfully installed tensorflow-addons-0.19.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"]}],"source":["!pip install -U tensorflow-addons"]},{"cell_type":"markdown","metadata":{},"source":["## Setup"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-12-17T11:54:42.802371Z","iopub.status.busy":"2023-12-17T11:54:42.802046Z","iopub.status.idle":"2023-12-17T11:54:48.563692Z","shell.execute_reply":"2023-12-17T11:54:48.562988Z","shell.execute_reply.started":"2023-12-17T11:54:42.802311Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). \n"," The versions of TensorFlow you are currently using is 2.6.2 and is not supported. \n","Some things might work, some things might not.\n","If you were to encounter a bug, do not file an issue.\n","If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n","You can find the compatibility matrix in TensorFlow Addon's readme:\n","https://github.com/tensorflow/addons\n","  UserWarning,\n"]}],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import os\n","from keras.preprocessing.image import ImageDataGenerator\n","import pandas as pd\n","import numpy as np\n","import os\n","from sklearn.metrics import confusion_matrix\n","#import seaborn as sn; sn.set(font_scale=1.4)\n","from sklearn.utils import shuffle           \n","import matplotlib.pyplot as plt             \n","import cv2                                 \n","import tensorflow as tf                \n","from tqdm import tqdm\n","#from sklearn.metrics import classification_report, log_loss, accuracy_score\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n","from keras.utils import np_utils\n","import tensorflow as tf\n","import datetime\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-12-17T11:54:49.404035Z","iopub.status.busy":"2023-12-17T11:54:49.403791Z","iopub.status.idle":"2023-12-17T11:54:49.409402Z","shell.execute_reply":"2023-12-17T11:54:49.408543Z","shell.execute_reply.started":"2023-12-17T11:54:49.404005Z"},"trusted":true},"outputs":[],"source":["class_names = ['glioma_tumor','meningioma_tumor','no_tumor','pituitary_tumor']\n","class_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n","\n","nb_classes = len(class_names)\n","\n","IMAGE_SIZE = (128, 128)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-12-17T11:55:24.287542Z","iopub.status.busy":"2023-12-17T11:55:24.287275Z","iopub.status.idle":"2023-12-17T11:55:24.300565Z","shell.execute_reply":"2023-12-17T11:55:24.299717Z","shell.execute_reply.started":"2023-12-17T11:55:24.287512Z"},"trusted":true},"outputs":[],"source":["patch_size = (32, 32)  # 2-by-2 sized patches\n","dropout_rate = 0.03  # Dropout rate\n","num_heads =8  # Attention heads\n","embed_dim = 64  # Embedding dimension\n","num_mlp = 256  # MLP layer size\n","qkv_bias = True  # Convert embedded patches to query, key, and values with a learnable additive value\n","window_size = 2  # Size of attention window\n","shift_size = 1  # Size of shifting window\n","image_dimension = 128  # Initial image size\n","\n","num_patch_x = input_shape[0] // patch_size[0]\n","num_patch_y = input_shape[1] // patch_size[1]\n","\n","learning_rate = 2e-5\n","batch_size = 64\n","num_epochs = 40\n","validation_split = 0.1\n","weight_decay = 0.0001\n","label_smoothing = 0.1"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-12-17T11:55:24.301877Z","iopub.status.busy":"2023-12-17T11:55:24.301651Z","iopub.status.idle":"2023-12-17T11:55:24.317288Z","shell.execute_reply":"2023-12-17T11:55:24.316482Z","shell.execute_reply.started":"2023-12-17T11:55:24.301849Z"},"trusted":true},"outputs":[],"source":["\n","def window_partition(x, window_size):\n","    _, height, width, channels = x.shape\n","    patch_num_y = height // window_size\n","    patch_num_x = width // window_size\n","    x = tf.reshape(\n","        x, shape=(-1, patch_num_y, window_size, patch_num_x, window_size, channels)\n","    )\n","    x = tf.transpose(x, (0, 1, 3, 2, 4, 5))\n","    windows = tf.reshape(x, shape=(-1, window_size, window_size, channels))\n","    return windows\n","\n","\n","def window_reverse(windows, window_size, height, width, channels):\n","    patch_num_y = height // window_size\n","    patch_num_x = width // window_size\n","    x = tf.reshape(\n","        windows,\n","        shape=(-1, patch_num_y, patch_num_x, window_size, window_size, channels),\n","    )\n","    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n","    x = tf.reshape(x, shape=(-1, height, width, channels))\n","    return x\n","\n","\n","class DropPath(layers.Layer):\n","    def __init__(self, drop_prob=None, **kwargs):\n","        super(DropPath, self).__init__(**kwargs)\n","        self.drop_prob = drop_prob\n","\n","    def call(self, x):\n","        input_shape = tf.shape(x)\n","        batch_size = input_shape[0]\n","        rank = x.shape.rank\n","        shape = (batch_size,) + (1,) * (rank - 1)\n","        random_tensor = (1 - self.drop_prob) + tf.random.uniform(shape, dtype=x.dtype)\n","        path_mask = tf.floor(random_tensor)\n","        output = tf.math.divide(x, 1 - self.drop_prob) * path_mask\n","        return output\n"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-12-17T11:55:24.319283Z","iopub.status.busy":"2023-12-17T11:55:24.318705Z","iopub.status.idle":"2023-12-17T11:55:24.347819Z","shell.execute_reply":"2023-12-17T11:55:24.346873Z","shell.execute_reply.started":"2023-12-17T11:55:24.319238Z"},"trusted":true},"outputs":[],"source":["\n","class WindowAttention(layers.Layer):\n","    def __init__(\n","        self, dim, window_size, num_heads, qkv_bias=True, dropout_rate=0.0, **kwargs\n","    ):\n","        super(WindowAttention, self).__init__(**kwargs)\n","        self.dim = dim\n","        self.window_size = window_size\n","        self.num_heads = num_heads\n","        self.scale = (dim // num_heads) ** -0.5\n","        self.qkv = layers.Dense(dim * 3, use_bias=qkv_bias)\n","        self.dropout = layers.Dropout(dropout_rate)\n","        self.proj = layers.Dense(dim)\n","\n","    def build(self, input_shape):\n","        num_window_elements = (2 * self.window_size[0] - 1) * (\n","            2 * self.window_size[1] - 1\n","        )\n","        self.relative_position_bias_table = self.add_weight(\n","            shape=(num_window_elements, self.num_heads),\n","            initializer=tf.initializers.Zeros(),\n","            trainable=True,\n","        )\n","        coords_h = np.arange(self.window_size[0])\n","        coords_w = np.arange(self.window_size[1])\n","        coords_matrix = np.meshgrid(coords_h, coords_w, indexing=\"ij\")\n","        coords = np.stack(coords_matrix)\n","        coords_flatten = coords.reshape(2, -1)\n","        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n","        relative_coords = relative_coords.transpose([1, 2, 0])\n","        relative_coords[:, :, 0] += self.window_size[0] - 1\n","        relative_coords[:, :, 1] += self.window_size[1] - 1\n","        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n","        relative_position_index = relative_coords.sum(-1)\n","\n","        self.relative_position_index = tf.Variable(\n","            initial_value=tf.convert_to_tensor(relative_position_index), trainable=False\n","        )\n","\n","    def call(self, x, mask=None):\n","        _, size, channels = x.shape\n","        head_dim = channels // self.num_heads\n","        x_qkv = self.qkv(x)\n","        x_qkv = tf.reshape(x_qkv, shape=(-1, size, 3, self.num_heads, head_dim))\n","        x_qkv = tf.transpose(x_qkv, perm=(2, 0, 3, 1, 4))\n","        q, k, v = x_qkv[0], x_qkv[1], x_qkv[2]\n","        q = q * self.scale\n","        k = tf.transpose(k, perm=(0, 1, 3, 2))\n","        attn = q @ k\n","\n","        num_window_elements = self.window_size[0] * self.window_size[1]\n","        relative_position_index_flat = tf.reshape(\n","            self.relative_position_index, shape=(-1,)\n","        )\n","        relative_position_bias = tf.gather(\n","            self.relative_position_bias_table, relative_position_index_flat\n","        )\n","        relative_position_bias = tf.reshape(\n","            relative_position_bias, shape=(num_window_elements, num_window_elements, -1)\n","        )\n","        relative_position_bias = tf.transpose(relative_position_bias, perm=(2, 0, 1))\n","        attn = attn + tf.expand_dims(relative_position_bias, axis=0)\n","\n","        if mask is not None:\n","            nW = mask.get_shape()[0]\n","            mask_float = tf.cast(\n","                tf.expand_dims(tf.expand_dims(mask, axis=1), axis=0), tf.float32\n","            )\n","            attn = (\n","                tf.reshape(attn, shape=(-1, nW, self.num_heads, size, size))\n","                + mask_float\n","            )\n","            attn = tf.reshape(attn, shape=(-1, self.num_heads, size, size))\n","            attn = keras.activations.softmax(attn, axis=-1)\n","        else:\n","            attn = keras.activations.softmax(attn, axis=-1)\n","        attn = self.dropout(attn)\n","\n","        x_qkv = attn @ v\n","        x_qkv = tf.transpose(x_qkv, perm=(0, 2, 1, 3))\n","        x_qkv = tf.reshape(x_qkv, shape=(-1, size, channels))\n","        x_qkv = self.proj(x_qkv)\n","        x_qkv = self.dropout(x_qkv)\n","        return x_qkv\n"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-12-17T11:55:24.349398Z","iopub.status.busy":"2023-12-17T11:55:24.349130Z","iopub.status.idle":"2023-12-17T11:55:24.378908Z","shell.execute_reply":"2023-12-17T11:55:24.377933Z","shell.execute_reply.started":"2023-12-17T11:55:24.349356Z"},"trusted":true},"outputs":[],"source":["\n","class SwinTransformer(layers.Layer):\n","    def __init__(\n","        self,\n","        dim,\n","        num_patch,\n","        num_heads,\n","        window_size=7,\n","        shift_size=0,\n","        num_mlp=1024,\n","        qkv_bias=True,\n","        dropout_rate=0.0,\n","        **kwargs,\n","    ):\n","        super(SwinTransformer, self).__init__(**kwargs)\n","\n","        self.dim = dim  # number of input dimensions\n","        self.num_patch = num_patch  # number of embedded patches\n","        self.num_heads = num_heads  # number of attention heads\n","        self.window_size = window_size  # size of window\n","        self.shift_size = shift_size  # size of window shift\n","        self.num_mlp = num_mlp  # number of MLP nodes\n","\n","        self.norm1 = layers.LayerNormalization(epsilon=1e-5)\n","        self.attn = WindowAttention(\n","            dim,\n","            window_size=(self.window_size, self.window_size),\n","            num_heads=num_heads,\n","            qkv_bias=qkv_bias,\n","            dropout_rate=dropout_rate,\n","        )\n","        self.drop_path = DropPath(dropout_rate)\n","        self.norm2 = layers.LayerNormalization(epsilon=1e-5)\n","\n","        self.mlp = keras.Sequential(\n","            [\n","                layers.Dense(num_mlp),\n","                layers.Activation(keras.activations.gelu),\n","                layers.Dropout(dropout_rate),\n","                layers.Dense(dim),\n","                layers.Dropout(dropout_rate),\n","            ]\n","        )\n","\n","        if min(self.num_patch) < self.window_size:\n","            self.shift_size = 0\n","            self.window_size = min(self.num_patch)\n","\n","    def build(self, input_shape):\n","        if self.shift_size == 0:\n","            self.attn_mask = None\n","        else:\n","            height, width = self.num_patch\n","            h_slices = (\n","                slice(0, -self.window_size),\n","                slice(-self.window_size, -self.shift_size),\n","                slice(-self.shift_size, None),\n","            )\n","            w_slices = (\n","                slice(0, -self.window_size),\n","                slice(-self.window_size, -self.shift_size),\n","                slice(-self.shift_size, None),\n","            )\n","            mask_array = np.zeros((1, height, width, 1))\n","            count = 0\n","            for h in h_slices:\n","                for w in w_slices:\n","                    mask_array[:, h, w, :] = count\n","                    count += 1\n","            mask_array = tf.convert_to_tensor(mask_array)\n","\n","            # mask array to windows\n","            mask_windows = window_partition(mask_array, self.window_size)\n","            mask_windows = tf.reshape(\n","                mask_windows, shape=[-1, self.window_size * self.window_size]\n","            )\n","            attn_mask = tf.expand_dims(mask_windows, axis=1) - tf.expand_dims(\n","                mask_windows, axis=2\n","            )\n","            attn_mask = tf.where(attn_mask != 0, -100.0, attn_mask)\n","            attn_mask = tf.where(attn_mask == 0, 0.0, attn_mask)\n","            self.attn_mask = tf.Variable(initial_value=attn_mask, trainable=False)\n","\n","    def call(self, x):\n","        height, width = self.num_patch\n","        _, num_patches_before, channels = x.shape\n","        x_skip = x\n","        x = self.norm1(x)\n","        x = tf.reshape(x, shape=(-1, height, width, channels))\n","        if self.shift_size > 0:\n","            shifted_x = tf.roll(\n","                x, shift=[-self.shift_size, -self.shift_size], axis=[1, 2]\n","            )\n","        else:\n","            shifted_x = x\n","\n","        x_windows = window_partition(shifted_x, self.window_size)\n","        x_windows = tf.reshape(\n","            x_windows, shape=(-1, self.window_size * self.window_size, channels)\n","        )\n","        attn_windows = self.attn(x_windows, mask=self.attn_mask)\n","\n","        attn_windows = tf.reshape(\n","            attn_windows, shape=(-1, self.window_size, self.window_size, channels)\n","        )\n","        shifted_x = window_reverse(\n","            attn_windows, self.window_size, height, width, channels\n","        )\n","        if self.shift_size > 0:\n","            x = tf.roll(\n","                shifted_x, shift=[self.shift_size, self.shift_size], axis=[1, 2]\n","            )\n","        else:\n","            x = shifted_x\n","\n","        x = tf.reshape(x, shape=(-1, height * width, channels))\n","        x = self.drop_path(x)\n","        x = x_skip + x\n","        x_skip = x\n","        x = self.norm2(x)\n","        x = self.mlp(x)\n","        x = self.drop_path(x)\n","        x = x_skip + x\n","        return x\n"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-12-17T11:55:24.380526Z","iopub.status.busy":"2023-12-17T11:55:24.380265Z","iopub.status.idle":"2023-12-17T11:55:24.400750Z","shell.execute_reply":"2023-12-17T11:55:24.399934Z","shell.execute_reply.started":"2023-12-17T11:55:24.380496Z"},"trusted":true},"outputs":[],"source":["\n","class PatchExtract(layers.Layer):\n","    def __init__(self, patch_size, **kwargs):\n","        super(PatchExtract, self).__init__(**kwargs)\n","        self.patch_size_x = patch_size[0]\n","        self.patch_size_y = patch_size[0]\n","\n","    def call(self, images):\n","        batch_size = tf.shape(images)[0]\n","        patches = tf.image.extract_patches(\n","            images=images,\n","            sizes=(1, self.patch_size_x, self.patch_size_y, 1),\n","            strides=(1, self.patch_size_x, self.patch_size_y, 1),\n","            rates=(1, 1, 1, 1),\n","            padding=\"VALID\",\n","        )\n","        patch_dim = patches.shape[-1]\n","        patch_num = patches.shape[1]\n","        return tf.reshape(patches, (batch_size, patch_num * patch_num, patch_dim))\n","\n","\n","class PatchEmbedding(layers.Layer):\n","    def __init__(self, num_patch, embed_dim, **kwargs):\n","        super(PatchEmbedding, self).__init__(**kwargs)\n","        self.num_patch = num_patch\n","        self.proj = layers.Dense(embed_dim)\n","        self.pos_embed = layers.Embedding(input_dim=num_patch, output_dim=embed_dim)\n","\n","    def call(self, patch):\n","        pos = tf.range(start=0, limit=self.num_patch, delta=1)\n","        return self.proj(patch) + self.pos_embed(pos)\n","\n","\n","class PatchMerging(tf.keras.layers.Layer):\n","    def __init__(self, num_patch, embed_dim):\n","        super(PatchMerging, self).__init__()\n","        self.num_patch = num_patch\n","        self.embed_dim = embed_dim\n","        self.linear_trans = layers.Dense(2 * embed_dim, use_bias=False)\n","\n","    def call(self, x):\n","        height, width = self.num_patch\n","        _, _, C = x.get_shape().as_list()\n","        x = tf.reshape(x, shape=(-1, height, width, C))\n","        x0 = x[:, 0::2, 0::2, :]\n","        x1 = x[:, 1::2, 0::2, :]\n","        x2 = x[:, 0::2, 1::2, :]\n","        x3 = x[:, 1::2, 1::2, :]\n","        x = tf.concat((x0, x1, x2, x3), axis=-1)\n","        x = tf.reshape(x, shape=(-1, (height // 2) * (width // 2), 4 * C))\n","        return self.linear_trans(x)\n"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-12-17T11:55:24.402287Z","iopub.status.busy":"2023-12-17T11:55:24.401993Z","iopub.status.idle":"2023-12-17T11:55:32.156764Z","shell.execute_reply":"2023-12-17T11:55:32.156079Z","shell.execute_reply.started":"2023-12-17T11:55:24.402244Z"},"trusted":true},"outputs":[],"source":["num_classes=4\n","input = layers.Input(input_shape)\n","x = layers.RandomCrop(image_dimension, image_dimension)(input)\n","x = layers.RandomFlip(\"horizontal\")(x)\n","x = PatchExtract(patch_size)(x)\n","x = PatchEmbedding(num_patch_x * num_patch_y, embed_dim)(x)\n","x = SwinTransformer(\n","    dim=embed_dim,\n","    num_patch=(num_patch_x, num_patch_y),\n","    num_heads=num_heads,\n","    window_size=window_size,\n","    shift_size=0,\n","    num_mlp=num_mlp,\n","    qkv_bias=qkv_bias,\n","    dropout_rate=dropout_rate,\n",")(x)\n","x = SwinTransformer(\n","    dim=embed_dim,\n","    num_patch=(num_patch_x, num_patch_y),\n","    num_heads=num_heads,\n","    window_size=window_size,\n","    shift_size=shift_size,\n","    num_mlp=num_mlp,\n","    qkv_bias=qkv_bias,\n","    dropout_rate=dropout_rate,\n",")(x)\n","x = PatchMerging((num_patch_x, num_patch_y), embed_dim=embed_dim)(x)\n","x = layers.GlobalAveragePooling1D()(x)\n","output = layers.Dense(num_classes, activation=\"softmax\")(x)"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2023-12-17T12:27:29.340063Z","iopub.status.busy":"2023-12-17T12:27:29.339757Z","iopub.status.idle":"2023-12-17T12:29:33.109250Z","shell.execute_reply":"2023-12-17T12:29:33.108386Z","shell.execute_reply.started":"2023-12-17T12:27:29.340029Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","18/18 [==============================] - 17s 743ms/step - loss: 0.5763 - accuracy: 0.9064 - top-5-accuracy: 1.0000 - val_loss: 0.4744 - val_accuracy: 0.9617 - val_top-5-accuracy: 1.0000\n","Epoch 2/10\n","18/18 [==============================] - 12s 659ms/step - loss: 0.4234 - accuracy: 0.9895 - top-5-accuracy: 1.0000 - val_loss: 0.4494 - val_accuracy: 0.9721 - val_top-5-accuracy: 1.0000\n","Epoch 3/10\n","18/18 [==============================] - 12s 665ms/step - loss: 0.4091 - accuracy: 0.9922 - top-5-accuracy: 1.0000 - val_loss: 0.4425 - val_accuracy: 0.9739 - val_top-5-accuracy: 1.0000\n","Epoch 4/10\n","18/18 [==============================] - 12s 651ms/step - loss: 0.3957 - accuracy: 0.9974 - top-5-accuracy: 1.0000 - val_loss: 0.4452 - val_accuracy: 0.9721 - val_top-5-accuracy: 1.0000\n","Epoch 5/10\n","18/18 [==============================] - 12s 674ms/step - loss: 0.3923 - accuracy: 0.9961 - top-5-accuracy: 1.0000 - val_loss: 0.4321 - val_accuracy: 0.9774 - val_top-5-accuracy: 1.0000\n","Epoch 6/10\n","18/18 [==============================] - 12s 662ms/step - loss: 0.3888 - accuracy: 0.9978 - top-5-accuracy: 1.0000 - val_loss: 0.4315 - val_accuracy: 0.9739 - val_top-5-accuracy: 1.0000\n","Epoch 7/10\n","18/18 [==============================] - 11s 640ms/step - loss: 0.3889 - accuracy: 0.9965 - top-5-accuracy: 1.0000 - val_loss: 0.4373 - val_accuracy: 0.9721 - val_top-5-accuracy: 1.0000\n","Epoch 8/10\n","18/18 [==============================] - 12s 657ms/step - loss: 0.3908 - accuracy: 0.9952 - top-5-accuracy: 1.0000 - val_loss: 0.4350 - val_accuracy: 0.9739 - val_top-5-accuracy: 1.0000\n","Epoch 9/10\n","18/18 [==============================] - 12s 658ms/step - loss: 0.3880 - accuracy: 0.9974 - top-5-accuracy: 1.0000 - val_loss: 0.4324 - val_accuracy: 0.9756 - val_top-5-accuracy: 1.0000\n","Epoch 10/10\n","18/18 [==============================] - 12s 669ms/step - loss: 0.3863 - accuracy: 0.9978 - top-5-accuracy: 1.0000 - val_loss: 0.4463 - val_accuracy: 0.9617 - val_top-5-accuracy: 1.0000\n"]}],"source":["model = keras.Model(input, output)\n","model.compile(\n","    loss=keras.losses.CategoricalCrossentropy(label_smoothing=label_smoothing),\n","    optimizer=keras.optimizers.Adam(learning_rate=1e-3, decay=weight_decay),\n","    metrics=[\n","        keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n","        keras.metrics.TopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n","    ],\n",")\n","\n","history = model.fit(\n","    train,\n","    epochs=10,\n","    validation_data=val,\n",")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":672377,"sourceId":1183165,"sourceType":"datasetVersion"},{"datasetId":1194525,"sourceId":1997093,"sourceType":"datasetVersion"},{"datasetId":1608934,"sourceId":2645886,"sourceType":"datasetVersion"}],"dockerImageVersionId":30177,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
